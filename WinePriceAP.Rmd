---
title: "Wine Price Analysis/Predictor"
author: "Cong Feng"
date: "12/15/2020"
output: pdf_document:
  df_print: kable
  number_section: yes
  toc: true
highlight-style: kate
mainfont: Calibri-light
fontsize: 10pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(caret)) install.packages("caret")
if(!require(ggplot2)) install.packages(ggplot2)
if(!require(knitr)) install.packages(knitr)

library(tidyverse)
library(caret)
library(ggplot2)
library(knitr)
```
# Introduction

In this project we are going to explore the relation between wines, ratings and price. As a wine enthusiast, one of the main factors that I look for when trying new wine is their rating, type of wine and where the wine came from. Today I will be working with a data set that includes all of those factors. 

The data is downloded from https://www.kaggle.com/zynicide/wine-reviews , the user scrapped the data from wineEnthusiast during the week of June 15th 2017. 

The goal I have set for this project is to analyze to see how each of the factors correlates with the price of wine. Then use these predictors to predict the price of each wine. To determine the accuracy of the prediction, we will calculate the "Root Mean Square Error" between the predicted price and actual price.

The formula is defined:
$$RMSE =\sqrt{\frac{1}{N}\sum_{u,i}(\hat{y}_{i}-y_{i})^2}$$
```{r message=FALSE, warning=FALSE}
RMSE <- function(predicted_price, actual_price){
  sqrt(mean((predicted_price - actual_price)^2))
}
```

# Data Loading and Wrangling

```{r Loading Data, message=FALSE, warning=FALSE, echo=FALSE}
# Download the file and load into R data
# This data is originally from https://www.kaggle.com/zynicide/wine-reviews
# I downloaded the file and uploaded to github for ease of access and you don't need to have a Kaggle account to download the dataset.

dl <- tempfile()
download.file("https://raw.githubusercontent.com/yumski/wine-price/master/winemag-data-130k-v2.csv", dl)
dat <- read.csv(dl)

rm(dl)
head(dat)
```
Here we see the first few rows of the data, there are a lot of information available to us. I will tidy the data and only keep the columns I plan to use.
```{r message=FALSE, warning=FALSE}
new_dat <- dat %>%
  select(X, country, points, price, title, variety, winery)

head(new_dat)
```
We can observe the titles includes the year that the wine is produce. We can extract this important information and store in it's own column.
```{r Extract Year, message=FALSE, warning=FALSE}
pattern <- "\\d{4}"
year <- str_extract(new_dat$title, pattern)

new_dat <- new_dat %>%
  mutate(years = year)

# Filter out NAs from dataset
new_dat <- new_dat %>%
  filter(!is.na(price), !is.na(points), !is.na(country), !is.na(variety), !is.na(years), !is.na(winery))


head(new_dat)
```
The most important rule in machine learning is to not train on data that will be tested on. This is to prevent over training and over smoothing. For the last part of data wrangling is to divide the data into a modeling/training set and a validation set. It will be a 90/10% split.
```{r message=FALSE, warning=FALSE}
set.seed(123, sample.kind = "Rounding")

ind <- createDataPartition(new_dat$price, times=1, p=0.1, list=FALSE)
wine_dat <- new_dat[-ind,]
validate_dat <- new_dat[ind,]
```

# Data Analysis

To begin the data analysis, first we will take a look at the dimension of the dataset.
```{r message=FALSE, warning=FALSE}
dim(wine_dat)
```
There are 108875 total entries for our training set.
```{r echo=FALSE, message=FALSE, warning=FALSE}
data.frame(Country = length(unique(wine_dat$country)),
           Points = length(unique(wine_dat$points)),
           Price = length(unique(wine_dat$price)),
           Province = length(unique(wine_dat$province)),
           Taster_name = length(unique(wine_dat$taster_name)),
           Title = length(unique(wine_dat$title)),
           Variety = length(unique(wine_dat$variety)),
           Winery = length(unique(wine_dat$winery)),
           Year = length(unique(wine_dat$years)))
```
Here is the breakdown of unique entries in each column. We see there are only 21 unique entries in the points column, which is strange because the point scale is out of 100.
```{r message=FALSE, warning=FALSE}
c(min(wine_dat$points), max(wine_dat$points))
```
We see the point distribution is actually from 80 to 100, this is an important piece of information for us to proceed with. A consumer might assumes 80 is a relatively high score, however it's actually the lowest score they give.
```{r message=FALSE, warning=FALSE}
c(min(wine_dat$price), max(wine_dat$price))
```
The price covers a wide range of wines as well. In this data, it covers everything from 4USD to 2500USD.

## Breakdown by Country
```{r echo=FALSE, warning=FALSE, message=FALSE}
wine_dat %>%
  group_by(country) %>%
  summarize(n = n()) %>%
  ggplot(aes(n, country)) +
  geom_point() +
  scale_x_sqrt() +
  xlab("Count (Square Root scale)") +
  ylab("Country") +
  theme_hc() +
  ggtitle("Country Count Distribution",
          subtitle = "Figure 1")
```
Here is the breakdown of the number of entries each country is represented in the data. We see that majority of the entries are from 4 countries: US, France, Spain and Italy. This is not surprising as these 4 countries are the largest producers of wine.
```{r echo=FALSE, warning=FALSE, message=FALSE}
wine_dat %>%
  group_by(country) %>%
  summarize(n = n(), price = price, country = country) %>%
  filter(n > 500) %>%
  ggplot(aes(country, price)) +
  geom_boxplot() +
  scale_y_log10() +
  xlab("Country") +
  ylab("Price (Log 10 scale)") +
  theme(axis.text.x=element_text(angle=90,hjust=1)) +
  theme_hc() +
  ggtitle("Price by Country",
          subtitle = "Figure 2")
```
This graph breaks down the price distribution for countries with over 500 entries. Each rectangle represents the 25 to 75% percentile for the price, the line inside the rectangle represents the median price. This means the larger the triangle, the higher variance of the price in that relative country.

We see from this graph that the US has the highest average price with average size variance. Chile has the lowest variance and the lowest average price. France has the most wines in highest price percentile, however their average wine price is lower than the US.
```{r echo=FALSE, warning=FALSE, message=FALSE}
wine_dat %>%
  group_by(country) %>%
  summarize(n = n(), points = points, country = country) %>%
  filter(n > 500) %>%
  ggplot(aes(country, points)) +
  geom_boxplot() +
  xlab("Country") +
  ylab("Points") +
  theme(axis.text.x=element_text(angle=90, hjust=1)) +
  theme_hc() +
  ggtitle("Points by Country",
          subtitle = "Figure 3")
```
We will do the same breakdown for the points distribution. Germany, Austria and Australia has the highest average rating; Chile with the lowest average price also has the lowest average rating. However, despite having the highest average rating - none of those 3 countries have any wines that has the perfect score. Only US, France, Italy and Portugal have wines that received the perfect rating.
```{r echo=FALSE, warning=FALSE, message=FALSE}
wine_dat %>%
  group_by(country) %>%
  summarize(n = n(), price = price, country = country, avg_pts = mean(points), avg_p = mean(price)) %>%
  filter(n > 100) %>%
  arrange(desc(n)) %>%
  top_n(100) %>%
  ggplot(aes(avg_pts, avg_p, color = country)) +
  geom_point() +
  theme_hc() +
  xlab("Average Points") +
  ylab("Average Price") +
  ggtitle("Avg Price and Points by Country",
          subtitle = "Figure 4")
```
When the average price and points are compared, the points are very scattered. There is not a strong correlation between the average points and price when grouped by country. The country with the highest average points is ranked 9th when it comes to the average price.
```{r warning=FALSE, message=FALSE, echo=FALSE}
wine_dat %>%
  group_by(country) %>%
  summarize(n = n(), stan_dev = sd(price)) %>%
  mutate(group = cut(n,
                     breaks = c(0, mean(n), Inf),
                     labels = c("< than average", "> than average"))) %>%
  ggplot(aes(stan_dev, fill = group)) +
  geom_density(alpha = 0.5) +
  xlab("Standard Deviation") +
  ylab("Density") +
  theme_hc() +
  ggtitle("Price Standard Deviation by Country",
          subtitle = "Figure 5")

```
When we group the groups into greater and less than average number of ratings to compare the standard deviation; we see that the countries with less ratings has lower standard deviation. This does makes sense; the countries that were rated more has a wider quality range and their producers sell wines at more price points.
```{r warning=FALSE, message=FALSE}
country_avg <- wine_dat %>%
  group_by(country) %>%
  summarize(avg_pts = mean(points), avg_p = mean(price))

correlate <- data.frame(Category = "Category",
                        Correlation = "Correlation") 

correlate <- bind_rows(Category = "Country",
                       Correlation = cor(country_avg$avg_pts, country_avg$avg_p))
correlate
```
We can use the correlate function to calculate our findings, we will make it into a data tables so we can observe which category has the highest correlation with the wine's price. This function returns a range from -1 to 1, where -1 is negative correlation and 1 is positive.

The country category returned a 0.468, this means that it shows some positive correlation but not overwhelming.

## Breakdown by Variety
```{r echo=FALSE, warning=FALSE, message=FALSE}
wine_dat %>%
  group_by(variety) %>%
  summarize(n = n()) %>%
  filter(n > 500) %>%
  ggplot(aes(n, variety)) +
  geom_point() +
  scale_x_sqrt() +
  xlab("Count (Square Root Sclae)") +
  ylab("Variety")
  theme_hc() +
  ggtitle("Variety Count Distribution",
          subtitle = "Figure 6")
```
In this graph, I have plotted the variety of wine that has more than 500 entries. From the distribution by variety, the top 5 most rated wine types are: Pinot Noir, Chardonnay, Carbernet Sauvignon, Red Blend and Bordeaux-style Red Blend. Four out of the five most rated wines are red wines, only Chardonnay is a white wine.
```{r echo=FALSE, warning=FALSE, message=FALSE}
wine_dat %>%
  group_by(variety) %>%
  summarize(n = n(), price = price, points = points, variety = variety) %>%
  filter(n > 500) %>%
  ggplot(aes(variety, price)) +
  geom_boxplot() +
  scale_y_log10() +
  theme_hc() +
  xlab("Variety") +
  ylab("Price") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("Variety Price Distribution",
          subtitle = "Figure 7")
```
There aren't any distinct pattern emerging from this graph. The different types of wine have wide range of variance in price. Three out of the top five most rated wines are represented in the highest price range of over 1000USD. The Bordeaux-style Red Blend is the variety with the most wines there is that price range, however the average price for this wine is in line with the other varieties.
```{r message=FALSE, warning=FALSE, echo=FALSE}
wine_dat %>%
  group_by(variety) %>%
  summarize(n = n(), price = price, points = points, variety = variety) %>%
  filter(n > 500) %>%
  ggplot(aes(variety, points)) +
  geom_boxplot() +
  scale_y_log10() +
  xlab("Variety") +
  ylab("Points") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme_hc() +
  ggtitle("Variety Points Distribution",
          subtitle = "Figure 8")

```
Pinot Noir, the most rated wine also has one of the highest ratings as well. The Bordeaux Style Red Blend has a large variance in it's ratings same as it's price. Like the previous graph, it does not have a distinct pattern emerging.
```{r message=FALSE, warning=FALSE, echo=FALSE}
wine_dat %>%
  group_by(variety) %>%
  summarize(n = n(), avg_p = mean(price), avg_pts = mean(points), variety = variety) %>%
  filter(n > 500) %>%
  ggplot(aes(avg_pts, avg_p, color = variety)) +
  geom_point() +
  xlab("Average Points") +
  ylab("Average Price") +
  theme_hc() +
  ggtitle("Avg Points and Price by Variety",
          subtitle = "Figure 9")
```
There is linear distribution at the lower end of the average point scale (< 88). As it moves past that point the distribution becomes much more scattered. When broken down the variety, there is not a distinct pattern.
```{r warning=FALSE, message=FALSE, echo=FALSE}
wine_dat %>%
  group_by(variety) %>%
  summarize(n = n(), stan_dev = sd(price)) %>%
  mutate(group = cut(n,
                     breaks = c(0, mean(n), Inf),
                     labels = c("< than average", "> than average"))) %>%
  ggplot(aes(stan_dev, fill = group)) +
  geom_density(alpha = 0.5) +
  xlab("Standard Deviation") +
  ylab("Density") +
  theme_hc() +
  ggtitle("Price Standard Deviation by Variety",
          subtitle = "Figure 10")

```
The standard deviation graph for the variety category is similar to the one for the country category. We see lower standard deviation for the group that were rated less than the average amount. The variety of wine that were rated a lot are most likely to be the more popular ones. Therefore the producers is looking to produce both wines that are tranges from everyday consumers and also others for connoisseurs. 
```{r warning=FALSE, message=FALSE}
variety_avg <- wine_dat %>%
  group_by(variety) %>%
  summarize(avg_pts = mean(points), avg_p = mean(price))

correlate <- bind_rows(correlate,
                       data.frame(Category = "Variety",
                       Correlation = cor(variety_avg$avg_pts, variety_avg$avg_p)))
```
The variety correlation returned a 0.427, this is consistent with the finding of our data analysis. The different types of wine does not play a big role in affecting the price and points. This is an interesting find, prior to doing this project I had the misconception of the different type of wine has a drastic effect on the price and point.

## Breakdown by Year
```{r message=FALSE, warning=FALSE, echo=FALSE}
wine_dat %>%
  group_by(years) %>%
  summarize(n = n(), price = price, points = points, years = years) %>%
  filter(n > 100) %>%
  ggplot(aes(n, years)) +
  geom_point() +
  theme_hc() +
  xlab("Count") +
  ylab("Years") +
  ggtitle("Distribution by Year",
          subtitle = "Figure 11")
```
In this graph, we see that majority of the reviews of the wines in the list are for ones that are produced recently. The top 5 years with over 10,000 review each are between the year of 2010 to 2014. We know the climate is a big factor in grape/wine production, let's dig deeper into the data to see if there is any evidence of this affecting the price and points of the wines.
```{r message=FALSE, warning=FALSE, echo=FALSE}
wine_dat %>%
  group_by(years) %>%
  summarize(n = n(), points = points, price = price, years = years) %>%
  filter(n > 500, !is.na(years)) %>%
  ggplot(aes(years, price)) +
  geom_boxplot() +
  scale_y_log10() +
  theme_hc() + 
  xlab("Years") +
  ylab("Price (Log 10 Scale)") +
  ggtitle("Years Price Distribution",
          subtitle = "Figure 12")
```
In this graph we can observe that from the year 2006 to 2013, the distribution of the price is quite similar. The rectangles are very similar to each other in height and the top percentile, however there is more variation at the bottom percentile.

We can also observe that the year 2004 has the highest average price, however it did not have any wines in the in the extreme upper percentile of price. Alternatively, the most recent years in this data set (2016) has by far the lowest variance and price. Only 6 years has wines that are priced at over 1000USD, with the year 2009 has the most appearances.
```{r echo=FALSE, warning=FALSE, message=FALSE}
wine_dat %>%
  group_by(years) %>%
  summarize(n = n(), points = points, price = price, years = years) %>%
  filter(n > 500, !is.na(years)) %>%
  ggplot(aes(years, points)) +
  geom_boxplot() +
  theme_hc() +
  xlab("Years") +
  ylab("Points") +
  ggtitle("Years Points Distribution",
          subtitle = "Figure 13")
```
In the points distribution breakdown, we see that there are several groups of nearly identical distributions. Year 1999  to 2001, 2006 to 2011 and 2012 to 2014 are the 3 groups that falls into this pattern. When we refer back to Figure 9, we see that years 2012-2014 are the 3 years with the most ratings. We also can observe that there are only 6 years that has wines with perfect rating.
```{r echo=FALSE, warning=FALSE, message=FALSE}
wine_dat %>%
  group_by(years) %>%
  summarize(n = n(), avg_p = mean(price), avg_pts = mean(points), years = years) %>%
  filter(n > 100) %>%
  ggplot(aes(avg_pts, avg_p, color = years)) +
  geom_point() +
  theme_hc() +
  xlab("Average Points") +
  ylab("Average Price") +
  ggtitle("Avg Points and Price by Year",
          subtitle = "Figure 14")
```
This graph confirms our findings from the previous 2 figures. There are clusters of points around 3 price and rating areas. From these observations we can deduce that the climate is relatively similar in a period of few years. This effects the growth condition of the grapes and the quality of the wine.
```{r  echo=FALSE, message=FALSE, warning=FALSE}
wine_dat %>%
  group_by(years) %>%
  summarize(n = n(), stan_dev = sd(price)) %>%
  mutate(group = cut(n,
                     breaks = c(0, mean(n), Inf),
                     labels = c("< than average", "> than average"))) %>%
  ggplot(aes(stan_dev, fill = group)) +
  geom_density(alpha = 0.5) +
  xlab("Standard Deviation") +
  ylab("Density") +
  theme_hc() +
  ggtitle("Price Standard Deviation by Years",
          subtitle = "Figure 15")

```
The standard deviation for the years category is complete opposite of the breakdown for the country and variety groups. For the years that were rated more than the average, it is very concentrated. This is in line with our previous observations. Majority of the wines in this data set are from 2010 to 2016, we saw in the box plots that the distribution is quite similar. As the wine gets older it tends to be more rare, and those tend to be more expensive.
```{r warning=FALSE, message=FALSE}
years_avg <- wine_dat %>%
  group_by(years) %>%
  filter(!is.na(years)) %>%
  summarize(avg_pts = mean(points), avg_p = mean(price))

correlate <- bind_rows(correlate,
                       data.frame(
                         Category = "Years",
                         Correlation = cor(years_avg$avg_pts, years_avg$avg_p)
                       ))

correlate
```
When grouped by the years category, the average price and points showed the highest correlation so far. This further reinforce our finding from the visual analysis. Even though I had preconceived notion that the year of the wine is important, I did not think it was so much greater than the other categories.
## Breakdown by Winery

```{r echo=FALSE, message=FALSE, warning=FALSE}
wine_dat %>%
  group_by(winery) %>%
  summarize(n = n(), winery) %>%
  filter(n > 100) %>%
  ggplot(aes(n, winery)) +
  geom_point() +
  theme_hc() +
  ggtitle("Winery Count Distribution",
          subtitle = "Figure 16")
```
When we observe the breakdown by winery, we can conclude that the distribution is quite even. The most rated winery only has about 200 observations. The data set is not dominated by a few wineries unlike the country and years categories. Since there are many wineries used in this data set, we are only going to graph the ones were rated over 100 times.
```{r echo=FALSE, message=FALSE, warning=FALSE}
wine_dat %>%
  group_by(winery) %>%
  summarize(n = n(), winery, price, points) %>%
  filter(n > 100) %>%
  ggplot(aes(winery, price)) +
  geom_boxplot() +
  scale_y_log10() +
  xlab("Winery") +
  ylab("Price (Log 10 Scale)") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme_hc() +
  ggtitle("Price by Winery Distribution",
          subtitle = "Figure 17")
```
This boxplot is the opposite of the distribution for the years category (figure 10). This makes sense as some wineries are very reputable brands and can charge accordingly. The most expensive winery is Louis Latour, the median price for their wine is higher than all of the other winery's upper box limits. On the other end of the spectrum DFJ Vinhos is the cheapest winery, with the median price at 10USD. Next we will take a look at their respective points and see if the price is reflected in their rating.
```{r echo=FALSE, message=FALSE, warning=FALSE}
wine_dat %>%
  group_by(winery) %>%
  summarize(n = n(), winery, price, points) %>%
  filter(n > 100) %>%
  ggplot(aes(winery, points)) +
  geom_boxplot() +
  xlab("Winery") +
  ylab("Points") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme_hc() +
  ggtitle("Points by Winery Distribution",
          subtitle = "Figure 18")
```
When looking at the the points distribution, we see that even though Louis Latour is the most expensive winery, they do not have the highest average rating. The two wineries with the highest average ratings are William Selyem and Lynmar. Those 2 wineries are among the highest in median prices, however both of their variance in price are small compared to Louis Latour. On the other end of the spectrum, DFJ Vinhos is the cheapest wineries and they have also received the lowest median. However the Santa Ema winery has higher variance is has more wines rated lower than DFJ Vinhos.

```{r echo=FALSE, message=FALSE, warning=FALSE}
wine_dat %>%
  group_by(winery) %>%
  summarize(n = n(), winery = winery, avg_pts = mean(points), avg_p = mean(price)) %>%
  filter(n > 100) %>%
  ggplot(aes(avg_pts, avg_p, color = winery)) +
  geom_point() +
  xlab("Average Points") +
  ylab("Average Price") +
  theme_hc() +
  ggtitle("Avg Price and Points by Winery",
          subtitle = "Figure 19")
```
In the winery breakdown, we can observe a linear pattern emerging. All the points besides one (Louis Latour) fits on the linear progression line. 
```{r message=FALSE, warning=FALSE, echo=FALSE}
wine_dat %>%
  group_by(winery) %>%
  summarize(n = n(), stan_dev = sd(price)) %>%
  mutate(group = cut(n,
                     breaks = c(0, mean(n), Inf),
                     labels = c("< than average", "> than average"))) %>%
  ggplot(aes(stan_dev, fill = group)) +
  geom_density(alpha = 0.5) +
  xlab("Standard Deviation (Sq root scale)") +
  ylab("Density") +
  scale_x_sqrt() +
  theme_hc() +
  ggtitle("Price Standard Deviation by Winery",
          subtitle = "Figure 20")

```
When grouped by winery, the number of times each winery rated does not seem to play a bit part in the price variance. This does make sense as well, as reputable winery generally charge more for all their wines and vice versa.
```{r message=FALSE, warning=FALSE}
winery_avg <- wine_dat %>%
  group_by(winery) %>%
  summarize(winery = winery, avg_pts = mean(points), avg_p = mean(price))

correlate <- bind_rows(correlate, 
                       data.frame(Category = "Winery",
                                  Correlation = cor(winery_avg$avg_pts, winery_avg$avg_p)))
correlate
```
The winery category has the second highest correlation. Even though the previous graph showed a linear plot, we must remember those are only for wineries that was rated over 100 times. There are over 15000 unique wineries included in this data set. This leads to wineries with small numbers of reviews that skew the data. This is a important factor to consider during the modeling step.

## Breakdown by points

Finally we will dive into the points breakdown to see if we can find any insights.
```{r message=FALSE, warning=FALSE, echo=FALSE}
wine_dat %>%
  group_by(points) %>%
  summarize(n = n()) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 30, color = "black", fill = "blue") +
  ylab("Count") +
  theme_hc() +
  ggtitle("Points Count Distribution",
          subtitle = "Figure 21")
```
When we observe the distribution of the number of times each rating has been given, we see that there is a wide disparity between the counts. Out of the 21 different ratings, 10 was rated over 5,000 times - with 5 of those over 10,000 times. Out of the remaining 11, 7 of those has very few ratings and the 4 remaining were rated less than 2,500 times.
```{r message=FALSE, warning=FALSE, echo=FALSE}
wine_dat %>%
  group_by(points) %>%
  summarize(n = n(), points = points) %>%
  ggplot(aes(points, n)) +
  geom_line() +
  scale_y_log10() +
  ylab("Count (Log 10 scale)") +
  xlab("Points") +
  theme_hc() +
  ggtitle("Count by Points",
          subtitle = "Figure 22")
```
We can observe that from this graph the 5 points that were given the most is from 86-91. This makes sense as the middle in a normal distribution curve is the highest. As we move to the edges the number of times each rating was given goes down. This is especially apparent when we look at the range from 95 to 100, it shows a sharp decline in the number of times each rating was given. 
```{r message=FALSE, warning=FALSE, echo=FALSE}
wine_dat %>%
  group_by(points) %>%
  summarize(n = n(), stan_dev = sd(price)) %>%
  mutate(group = cut(n,
                     breaks = c(0, mean(n), Inf),
                     labels = c("< than avg", "> than avg"))) %>%
  ggplot(aes(stan_dev, fill = group)) +
  geom_density(alpha = 0.5) +
  xlab("Standard Deviation") +
  ylab("Density") +
  theme_hc() +
  ggtitle("Standard Deviation of Price - Points Group",
          subtitle = "Figure 23")
```
We can see a huge difference with the standard deviation when it was separated by the number of times each point was rated. The points that had was rated more than the average number has a relatively small standard deviation; the other group has a huge variance in the price.
```{r message=FALSE, warning=FALSE, echo=FALSE}
wine_dat %>%
  group_by(points) %>%
  summarize(avg_p = mean(price), points = points) %>%
  ggplot(aes(points, avg_p)) +
  geom_point() +
  xlab("Points") +
  ylab("Average Price") +
  theme_hc() +
  ggtitle("Average Price by Points",
          subtitle = "Figure 24")
```
There is an exponential curve when we plot the average price against the points. From the rating of 80 - 85 the average price is relatively flat. From 86 - 90 we begin to see increases, from 91+ we can observe exponential increases in the average price as the points increases. The average price of wines that were rated 100 is almost at 500USD per bottle. 
```{r warning=FALSE, message=FALSE}
pts_avg <- wine_dat %>%
  group_by(points) %>%
  summarize(avg_pts = mean(points), avg_p = mean(price))

correlate <- bind_rows(correlate, 
                       data.frame(Category = "Points",
                                  Correlation = cor(pts_avg$avg_pts, pts_avg$avg_p)))
correlate
```
We see there is strong correlation between the average price and it's relative point rating. This confirms our previous graph where we observed the exponential increase in price as the points increased. However, there is a large variance in the rating that were seldom given. 

# Modeling

For this project, we will use two machine learning models to create an ensemble for the lowest possible RMSE. To prevent over training we will further partition the data set. We will only apply the model to the validate set at the very end.
```{r message=FALSE, warning=FALSE}

# Partition data into train and test set
set.seed(111, sample.kind = "Rounding")
ind <- createDataPartition(wine_dat$price, times = 1, p = 0.1, list = FALSE)

train_dat <- wine_dat[-ind,]
temp <- wine_dat[ind,]

# Make sure the all the criteria are in both data sets
test_data <- temp %>%
  semi_join(train_dat, by = "country") %>%
  semi_join(train_dat, by = "variety") %>%
  semi_join(train_dat, by = "years") %>%
  semi_join(train_dat, by = "winery")
```

## Linear Regression Model

The first model we will explore is the linear regression model. This model takes into account the bias that effects the price in all 4 categories we examined. The formula will be:
$$\hat{y}_i=\mu+b_c+b_v+b_y+b_w+b_p$$
$$\hat{y}_i$$ is the Predicted price for wine $$i$$.
$$\\mu$$ is the average price of all the wines.
$$b_c$$ is the bias for the country.
$$b_v$$ is the bias for the variety of wine.
$$b_y$$ is the bias for the year the wine was produced.
$$b_w$$ is the bias for the winery that the wine was produced at.
$$b_p$$ is the bias for the point that each wine was rated.

First we will determine a baseline by predicting the average price to all the wines.
```{r message=FALSE, warning=FALSE}
mu <- mean(train_dat$price)

c(min(train_dat$price), max(train_dat$price))

result <- data.frame(Method = "Baseline",
                     RMSE = RMSE(mu, test_dat$price))

result
```
The RMSE baseline is rather substantial, however this is expected. The price range for the wines is 4 to 2500USD. This list include rare wines that can skew the numbers quite a bit. Let's factor in the other biases to see how that affects the RMSE.
```{r message=FALSE, warning=FALSE}
# Country bias
b_c <- train_dat %>%
  group_by(country) %>%
  summarize(b_c = mean(price - mu))

pred_bc <- test_data %>%
  left_join(b_c, by = "country") %>%
  mutate(pred = mu + b_c) %>%
  .$pred

result <- bind_rows(result, 
                    data.frame(Method = "Country Bias",
                               RMSE = RMSE(pred_bc, test_data$price)))
result
```
When the country bias was factored in, there is a slight increase in the RMSE. When looking back at our data analysis for the country category, we saw large standard deviation for the countries that were rated the most. Also the number of ratings in those countries made up a large proportion of the data set. Taking that into consideration it does make sense on why this negatively affected the RMSE.
```{r message=FALSE, warning=FALSE}
# Variety bias
b_v <- train_dat %>%
  group_by(variety) %>%
  summarize(b_v = mean(price - mu))

pred_bcv <- test_data %>%
  left_join(b_c, by = "country") %>%
  left_join(b_v, by = "variety") %>%
  mutate(pred = mu + b_c + b_v) %>%
  .$pred

result <- bind_rows(result, 
                    data.frame(Method = "Country + Variety",
                               RMSE = RMSE(pred_bcv, test_data$price)))
result
```
The variety bias has a small decrease in the RMSE when factored in. The standard deviation distribution is similar to the ones for the countries. However, the ratings in the variety category has 655 unique observations compared to only 43 for countries. This means the ratings were more distributed when compared to the countries category.
```{r message=FALSE, warning=FALSE}
# Years Bias
b_y <- train_dat %>%
  group_by(years) %>%
  summarize(b_y = mean(price - mu))

pred_bcvy <- test_data %>%
  left_join(b_c, by = "country") %>%
  left_join(b_v, by = "variety") %>%
  left_join(b_y, by = "years") %>%
  mutate(pred = mu + b_c + b_v + b_y) %>%
  .$pred


result <- bind_rows(result, 
                    data.frame(Method = "Country + Variety + Years",
                               RMSE = RMSE(pred_bcvy, test_data$price)))
result
```
There is a small decrease in the RMSE when factored in the years category. The standard deviation for the price was very concentrated for the years that were rated the most number of times. There is however large variance for the years that were not rated as much, we can address this when we apply regularization to the algorithm.
```{r message=FALSE, warning=FALSE}
# Winery Bias
b_w <- train_dat %>%
  group_by(winery) %>%
  summarize(b_w = mean(price - mu))

pred_bcvyw <- test_data %>%
  left_join(b_c, by = "country") %>%
  left_join(b_v, by = "variety") %>%
  left_join(b_y, by = "years") %>%
  left_join(b_w, by = "winery") %>%
  mutate(pred = mu + b_c + b_v + b_y + b_w) %>%
  .$pred

result <- bind_rows(result, 
                      data.frame(Method = "Country + Variety + Years + Winery",
                                 RMSE = RMSE(pred_bcvyw, test_data$price)))
result
```
There is a small decrease in the RMSE when factored in the years category. The standard deviation for the price was very concentrated for the years that were rated the most number of times. There is however large variance for the years that were not rated as much, we can address this when we apply regularization to the algorithm.
```{r message=FALSE, warning=FALSE}
# Points bias
b_p <- train_dat %>%
  group_by(points) %>%
  summarize(b_p = mean(price - mu))

pred_bcvywp <- test_data %>%
  left_join(b_c, by = "country") %>%
  left_join(b_v, by = "variety") %>%
  left_join(b_y, by = "years") %>%
  left_join(b_w, by = "winery") %>%
  left_join(b_p, by = "points") %>%
  mutate(pred = mu + b_c + b_v + b_y + b_w + b_p) %>%
  .$pred

result <- bind_rows(result, 
                    data.frame(Method = "Country + Variety + Years + Winery + Points",
                               RMSE = RMSE(pred_bcvywp, test_data$price)))
result
```

There is a large increase in the RMSE when accounting for the points bias. In the points standard deviation graph we observed that there is huge variance in the price of the less given points. We also observed that there is an exponential increase in the average price as the points went above 95. The same range where there is a sharp decrease in the number of ratings. This high variance with low number of ratings skewed the algorithm.

## Regularization

In the linear regression model, we observed some biases with low number of occurrence and high variance. The regularization method introduce a tuning parameter to control the variability. This method will shrink the bias towards 0 when there are low number of occurrence, but will be effectively ignored when there is high number of occurrences.

The formula we will use:
$$
\hat{y}_i= \frac{1}{\lambda + n_i} \sum_{u=1}^{n_i} \left(Y_{i} - b_v - b_y - b_w - b_p - \hat{\mu}\right)
$$
We will not be using the country bias due to the fact that we discovered the most rated countries actually had more variance compared to the seldom rated countries. Regularization will not be able to affect this, this method aims to provide more weight to the variables that appeared more in the data.

Lambda is a tuning parameter, we can use machine learning to determine what the value is to give the lowest RMSE. We will run the lambda at the range of 0.25 to 10 at 0.25 increments.
```{r message=FALSE, warning=FALSE}
# establish lambda range
lambdas <- seq(0.25, 10, 0.25)

# regularization function
regularization_rmse <- sapply(lambdas, function(l){
  # variety regularization
  bv_r <- train_dat %>%
    group_by(variety) %>%
    summarize(bv_r = sum(price - mu)/(n() + l))
  # years regularization
  by_r <- train_dat %>%
    left_join(bv_r, by = "variety") %>%
    group_by(years) %>%
    summarize(by_r = sum(price - bv_r - mu)/(n() + l))
  # winery regularization
  bw_r <- train_dat %>%
    left_join(bv_r, by = "variety") %>%
    left_join(by_r, by = "years") %>%
    group_by(winery) %>%
    summarize(bw_r = sum(price - bv_r - by_r - mu)/(n() + l))
  # points regularization
  bp_r <- train_dat %>%
    left_join(bv_r, by = "variety") %>%
    left_join(by_r, by = "years") %>%
    left_join(bw_r, by = "winery") %>%
    group_by(points) %>%
    summarize(bp_r = sum(price - bv_r - by_r - bw_r - mu)/(n() + l))
  # predict algorithm
  pred_reg <- test_data %>%
    left_join(bv_r, by = "variety") %>%
    left_join(by_r, by = "years") %>%
    left_join(bw_r, by = "winery") %>%
    left_join(bp_r, by = "points") %>%
    mutate(pred = mu + bv_r + by_r + bw_r + bp_r) %>%
    .$pred
  
  return(RMSE(pred_reg, test_data$price))
})

# Graph Lambdas vs RMSE
data.frame(Lambdas = lambdas, RMSE = regularization_rmse) %>%
  ggplot(aes(Lambdas, RMSE)) +
  geom_point() +
  theme_hc() +
  ggtitle("Lambdas vs RMSE Distribution")

lambda <- lambdas[which.min(regularization_rmse)]
lambda

result <- bind_rows(result,
                    data.frame(Method = "Regularization",
                               RMSE = min(regularization_rmse)))
result
```
The regularization provided a drastic decrease in the RMSE. We observe from the graph that the lambda at 1.5 provided the lowest RMSE at 29.79118.
